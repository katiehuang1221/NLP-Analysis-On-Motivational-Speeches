{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "(Topic modeling continued)\n",
    "Use Tf-idf and NMF\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.feature_extraction import text \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from gensim import matutils, models\n",
    "import scipy.sparse\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('/Users/katiehuang/Desktop/metis/projects/onl_ds5_project_4/py')\n",
    "from word_cloud import *\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36156, 441)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's read in our transcripts and document-term matrix\n",
    "speech_df = pd.read_pickle('../dump/speech_clean_lemma')\n",
    "data = pd.read_pickle('../dump/data_dtm_lemma.pkl')\n",
    "tdm = data.transpose()\n",
    "tdm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Topic modeling - NMF\n",
    "\n",
    "Besides LDA, there are other matrix factorization techniques such as Latent Semantic Indexing (**LSI**) and non-negative Matrix Factorization (**NMF**).\n",
    "\n",
    "NMF is similar to Principal component analysis (**PCA**), but NMF models are interpretable. Vectors are non-negative; by factoring them into the lower-dimensional form, coefficients are also non-negative.\n",
    "\n",
    "- Documents are expressed as combinations of topics\n",
    "- Images are expressed as combinations of patterns\n",
    "\n",
    "NMF has components (dimension of components = dimension of samples)  \n",
    "> **sample = feature * components**  \n",
    "> (transcript = _____ * topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "csr_mat = tfidf.fit_transform(speech_df['transcript'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(csr_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csr_mat.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aahhhh</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aback</th>\n",
       "      <th>abalthus</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abate</th>\n",
       "      <th>abbot</th>\n",
       "      <th>abbreviation</th>\n",
       "      <th>...</th>\n",
       "      <th>ôi</th>\n",
       "      <th>ômay</th>\n",
       "      <th>ôsobriety</th>\n",
       "      <th>ôtell</th>\n",
       "      <th>ôthe</th>\n",
       "      <th>ôwe</th>\n",
       "      <th>ôwhat</th>\n",
       "      <th>ôyou</th>\n",
       "      <th>ôyouõre</th>\n",
       "      <th>über</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows × 36466 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aa  aahhhh  aaron  aback  abalthus   abandon  abandonment  abate  abbot  \\\n",
       "0    0.0     0.0    0.0    0.0       0.0  0.012061          0.0    0.0    0.0   \n",
       "1    0.0     0.0    0.0    0.0       0.0  0.000000          0.0    0.0    0.0   \n",
       "2    0.0     0.0    0.0    0.0       0.0  0.000000          0.0    0.0    0.0   \n",
       "3    0.0     0.0    0.0    0.0       0.0  0.000000          0.0    0.0    0.0   \n",
       "4    0.0     0.0    0.0    0.0       0.0  0.000000          0.0    0.0    0.0   \n",
       "..   ...     ...    ...    ...       ...       ...          ...    ...    ...   \n",
       "436  0.0     0.0    0.0    0.0       0.0  0.000000          0.0    0.0    0.0   \n",
       "437  0.0     0.0    0.0    0.0       0.0  0.000000          0.0    0.0    0.0   \n",
       "438  0.0     0.0    0.0    0.0       0.0  0.000000          0.0    0.0    0.0   \n",
       "439  0.0     0.0    0.0    0.0       0.0  0.000000          0.0    0.0    0.0   \n",
       "440  0.0     0.0    0.0    0.0       0.0  0.000000          0.0    0.0    0.0   \n",
       "\n",
       "     abbreviation  ...   ôi  ômay  ôsobriety  ôtell  ôthe  ôwe  ôwhat  ôyou  \\\n",
       "0             0.0  ...  0.0   0.0        0.0    0.0   0.0  0.0    0.0   0.0   \n",
       "1             0.0  ...  0.0   0.0        0.0    0.0   0.0  0.0    0.0   0.0   \n",
       "2             0.0  ...  0.0   0.0        0.0    0.0   0.0  0.0    0.0   0.0   \n",
       "3             0.0  ...  0.0   0.0        0.0    0.0   0.0  0.0    0.0   0.0   \n",
       "4             0.0  ...  0.0   0.0        0.0    0.0   0.0  0.0    0.0   0.0   \n",
       "..            ...  ...  ...   ...        ...    ...   ...  ...    ...   ...   \n",
       "436           0.0  ...  0.0   0.0        0.0    0.0   0.0  0.0    0.0   0.0   \n",
       "437           0.0  ...  0.0   0.0        0.0    0.0   0.0  0.0    0.0   0.0   \n",
       "438           0.0  ...  0.0   0.0        0.0    0.0   0.0  0.0    0.0   0.0   \n",
       "439           0.0  ...  0.0   0.0        0.0    0.0   0.0  0.0    0.0   0.0   \n",
       "440           0.0  ...  0.0   0.0        0.0    0.0   0.0  0.0    0.0   0.0   \n",
       "\n",
       "     ôyouõre  über  \n",
       "0        0.0   0.0  \n",
       "1        0.0   0.0  \n",
       "2        0.0   0.0  \n",
       "3        0.0   0.0  \n",
       "4        0.0   0.0  \n",
       "..       ...   ...  \n",
       "436      0.0   0.0  \n",
       "437      0.0   0.0  \n",
       "438      0.0   0.0  \n",
       "439      0.0   0.0  \n",
       "440      0.0   0.0  \n",
       "\n",
       "[441 rows x 36466 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_dtm = pd.DataFrame(csr_mat.toarray(), columns=tfidf.get_feature_names())\n",
    "tfidf_dtm.index = speech_df.index\n",
    "tfidf_dtm.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle stop words\n",
    "add_stop_words = ['like','youre','ive','im','really','id','ve','just','dont','thi','wa',\n",
    "                  'say','know','make','people']\n",
    "\n",
    "boring_words = ['say','like','just','dont','don','im',\n",
    "                  'ive','youll','youve','things','thing','youre','right','really','lot',\n",
    "                  'make','know','people','way','day','class']\n",
    "\n",
    "import pickle\n",
    "with open(\"../dump/common_words.txt\", \"rb\") as f:   # Unpickling\n",
    "    common_words = pickle.load(f)\n",
    "    \n",
    "add_stop_words = add_stop_words + common_words + boring_words\n",
    "\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(add_stop_words)\n",
    "# stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_dtm(df,column_name,add_stop_words=[]):\n",
    "    \"\"\"\n",
    "    Input: corpus (Ex: speech_clean_2, 'transcript')\n",
    "    Output: Document-Term Matrix (rows: documents, columns: words)\n",
    "    \n",
    "    \"\"\"\n",
    "    tfidf = TfidfVectorizer(stop_words=stop_words)\n",
    "    data_tfidf = tfidf.fit_transform(df[column_name])\n",
    "\n",
    "    tfidf_dtm = pd.DataFrame(data_tfidf.toarray(), columns=tfidf.get_feature_names())\n",
    "    tfidf_dtm.index = df.index\n",
    "    \n",
    "    return tfidf_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aahhhh</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aback</th>\n",
       "      <th>abalthus</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abate</th>\n",
       "      <th>abbot</th>\n",
       "      <th>abbreviation</th>\n",
       "      <th>...</th>\n",
       "      <th>ôi</th>\n",
       "      <th>ômay</th>\n",
       "      <th>ôsobriety</th>\n",
       "      <th>ôtell</th>\n",
       "      <th>ôthe</th>\n",
       "      <th>ôwe</th>\n",
       "      <th>ôwhat</th>\n",
       "      <th>ôyou</th>\n",
       "      <th>ôyouõre</th>\n",
       "      <th>über</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021622</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows × 36120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aa  aahhhh  aaron  aback  abalthus   abandon  abandonment  abate  abbot  \\\n",
       "0    0.0     0.0    0.0    0.0       0.0  0.021622          0.0    0.0    0.0   \n",
       "1    0.0     0.0    0.0    0.0       0.0  0.000000          0.0    0.0    0.0   \n",
       "2    0.0     0.0    0.0    0.0       0.0  0.000000          0.0    0.0    0.0   \n",
       "3    0.0     0.0    0.0    0.0       0.0  0.000000          0.0    0.0    0.0   \n",
       "4    0.0     0.0    0.0    0.0       0.0  0.000000          0.0    0.0    0.0   \n",
       "..   ...     ...    ...    ...       ...       ...          ...    ...    ...   \n",
       "436  0.0     0.0    0.0    0.0       0.0  0.000000          0.0    0.0    0.0   \n",
       "437  0.0     0.0    0.0    0.0       0.0  0.000000          0.0    0.0    0.0   \n",
       "438  0.0     0.0    0.0    0.0       0.0  0.000000          0.0    0.0    0.0   \n",
       "439  0.0     0.0    0.0    0.0       0.0  0.000000          0.0    0.0    0.0   \n",
       "440  0.0     0.0    0.0    0.0       0.0  0.000000          0.0    0.0    0.0   \n",
       "\n",
       "     abbreviation  ...   ôi  ômay  ôsobriety  ôtell  ôthe  ôwe  ôwhat  ôyou  \\\n",
       "0             0.0  ...  0.0   0.0        0.0    0.0   0.0  0.0    0.0   0.0   \n",
       "1             0.0  ...  0.0   0.0        0.0    0.0   0.0  0.0    0.0   0.0   \n",
       "2             0.0  ...  0.0   0.0        0.0    0.0   0.0  0.0    0.0   0.0   \n",
       "3             0.0  ...  0.0   0.0        0.0    0.0   0.0  0.0    0.0   0.0   \n",
       "4             0.0  ...  0.0   0.0        0.0    0.0   0.0  0.0    0.0   0.0   \n",
       "..            ...  ...  ...   ...        ...    ...   ...  ...    ...   ...   \n",
       "436           0.0  ...  0.0   0.0        0.0    0.0   0.0  0.0    0.0   0.0   \n",
       "437           0.0  ...  0.0   0.0        0.0    0.0   0.0  0.0    0.0   0.0   \n",
       "438           0.0  ...  0.0   0.0        0.0    0.0   0.0  0.0    0.0   0.0   \n",
       "439           0.0  ...  0.0   0.0        0.0    0.0   0.0  0.0    0.0   0.0   \n",
       "440           0.0  ...  0.0   0.0        0.0    0.0   0.0  0.0    0.0   0.0   \n",
       "\n",
       "     ôyouõre  über  \n",
       "0        0.0   0.0  \n",
       "1        0.0   0.0  \n",
       "2        0.0   0.0  \n",
       "3        0.0   0.0  \n",
       "4        0.0   0.0  \n",
       "..       ...   ...  \n",
       "436      0.0   0.0  \n",
       "437      0.0   0.0  \n",
       "438      0.0   0.0  \n",
       "439      0.0   0.0  \n",
       "440      0.0   0.0  \n",
       "\n",
       "[441 rows x 36120 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_dtm(speech_df,'transcript').iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means (clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(svd,kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('truncatedsvd', TruncatedSVD(n_components=50)),\n",
       "                ('kmeans', KMeans(n_clusters=6))])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(csr_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pipeline.predict(csr_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = list(speech_df.speaker)\n",
    "# speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     label           speaker\n",
      "343      0    YVONNE THORTON\n",
      "160      0      RONAN FARROW\n",
      "161      0      SANJAY GUPTA\n",
      "378      0  CHARLES W COLSON\n",
      "164      0         NEIL HOWE\n",
      "..     ...               ...\n",
      "327      4       EARL BAKKEN\n",
      "141      4    LOUIS B SUSMAN\n",
      "305      4    CHRIS MATTHEWS\n",
      "193      5     CYNTHIA ENLOE\n",
      "106      5     HOWARD GORDON\n",
      "\n",
      "[441 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'label': labels, 'speaker': speakers})\n",
    "print(df.sort_values('label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF (DataCamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1076: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NMF(n_components=6)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NMF(n_components=6)\n",
    "model.fit(csr_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_features = model.transform(csr_mat)\n",
    "# nmf_features\n",
    "\n",
    "# Normalize the NMF features\n",
    "from sklearn.preprocessing import normalize\n",
    "norm_features = normalize(nmf_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.21556158e-04 6.19164339e-04 0.00000000e+00 ... 0.00000000e+00\n",
      "  2.06031355e-04 5.05794754e-04]\n",
      " [0.00000000e+00 0.00000000e+00 8.06709914e-04 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.96972481e-04 1.02116101e-03 1.84263374e-04 ... 6.74867788e-04\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 8.61977402e-05\n",
      "  2.23903489e-04 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 5.90565900e-04 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.16586241e-03 0.00000000e+00 1.21690093e-03 ... 6.12141228e-04\n",
      "  7.25312323e-04 3.22254312e-04]]\n"
     ]
    }
   ],
   "source": [
    "print(model.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SIDDHARTHA MUKHERJEE</th>\n",
       "      <td>0.031866</td>\n",
       "      <td>0.169803</td>\n",
       "      <td>0.040845</td>\n",
       "      <td>0.075233</td>\n",
       "      <td>0.095660</td>\n",
       "      <td>0.194245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABBY WAMBACK</th>\n",
       "      <td>0.170827</td>\n",
       "      <td>0.135767</td>\n",
       "      <td>0.025368</td>\n",
       "      <td>0.117366</td>\n",
       "      <td>0.044826</td>\n",
       "      <td>0.026893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JON B. FISHER</th>\n",
       "      <td>0.097421</td>\n",
       "      <td>0.044180</td>\n",
       "      <td>0.089495</td>\n",
       "      <td>0.008672</td>\n",
       "      <td>0.112430</td>\n",
       "      <td>0.207049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MINDY KALING</th>\n",
       "      <td>0.143041</td>\n",
       "      <td>0.077636</td>\n",
       "      <td>0.139013</td>\n",
       "      <td>0.125458</td>\n",
       "      <td>0.012049</td>\n",
       "      <td>0.055104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JESMYN WARD</th>\n",
       "      <td>0.187328</td>\n",
       "      <td>0.052544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041931</td>\n",
       "      <td>0.084480</td>\n",
       "      <td>0.192366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CARRIE CHAPMAN</th>\n",
       "      <td>0.087265</td>\n",
       "      <td>0.244183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044966</td>\n",
       "      <td>0.100617</td>\n",
       "      <td>0.050038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FRANKLIN D ROOSEVELT</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.260075</td>\n",
       "      <td>0.007759</td>\n",
       "      <td>0.089358</td>\n",
       "      <td>0.174171</td>\n",
       "      <td>0.079200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPRAH WINFREY</th>\n",
       "      <td>0.116104</td>\n",
       "      <td>0.010120</td>\n",
       "      <td>0.185028</td>\n",
       "      <td>0.145698</td>\n",
       "      <td>0.073371</td>\n",
       "      <td>0.050137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RALPH WALDO</th>\n",
       "      <td>0.071360</td>\n",
       "      <td>0.278450</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>0.083856</td>\n",
       "      <td>0.141080</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GARRISON KEILLOR</th>\n",
       "      <td>0.007890</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.195040</td>\n",
       "      <td>0.073522</td>\n",
       "      <td>0.195081</td>\n",
       "      <td>0.110089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0         1         2         3         4  \\\n",
       "SIDDHARTHA MUKHERJEE  0.031866  0.169803  0.040845  0.075233  0.095660   \n",
       "ABBY WAMBACK          0.170827  0.135767  0.025368  0.117366  0.044826   \n",
       "JON B. FISHER         0.097421  0.044180  0.089495  0.008672  0.112430   \n",
       "MINDY KALING          0.143041  0.077636  0.139013  0.125458  0.012049   \n",
       "JESMYN WARD           0.187328  0.052544  0.000000  0.041931  0.084480   \n",
       "...                        ...       ...       ...       ...       ...   \n",
       "CARRIE CHAPMAN        0.087265  0.244183  0.000000  0.044966  0.100617   \n",
       "FRANKLIN D ROOSEVELT  0.000000  0.260075  0.007759  0.089358  0.174171   \n",
       "OPRAH WINFREY         0.116104  0.010120  0.185028  0.145698  0.073371   \n",
       "RALPH WALDO           0.071360  0.278450  0.001799  0.083856  0.141080   \n",
       "GARRISON KEILLOR      0.007890  0.000000  0.195040  0.073522  0.195081   \n",
       "\n",
       "                             5  \n",
       "SIDDHARTHA MUKHERJEE  0.194245  \n",
       "ABBY WAMBACK          0.026893  \n",
       "JON B. FISHER         0.207049  \n",
       "MINDY KALING          0.055104  \n",
       "JESMYN WARD           0.192366  \n",
       "...                        ...  \n",
       "CARRIE CHAPMAN        0.050038  \n",
       "FRANKLIN D ROOSEVELT  0.079200  \n",
       "OPRAH WINFREY         0.050137  \n",
       "RALPH WALDO           0.000000  \n",
       "GARRISON KEILLOR      0.110089  \n",
       "\n",
       "[441 rows x 6 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(nmf_features,index=speakers)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommender: cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommender using cosine similarity\n",
    "\n",
    "df = pd.DataFrame(norm_features,index=speakers)\n",
    "transcript = df.iloc[0]\n",
    "similarities = df.dot(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIDDHARTHA MUKHERJEE    1.000000\n",
      "DAVID BRODER            0.985673\n",
      "JOHN LEGEND             0.977784\n",
      "JIM STEEN               0.969246\n",
      "JANET YELLEN            0.964553\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Find speeches most similar to that of SIDDHARTHA MUKHERJEE\n",
    "print(similarities.nlargest())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAY LENO           0.194285\n",
      "JACK BLACK         0.246147\n",
      "RICHARD COSTOLO    0.254357\n",
      "SANDRA BULLOCK     0.283517\n",
      "MAYA RUDOLPH       0.294764\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(similarities.nsmallest())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF (Vinny's lecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(441, 36168)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words = 'english')\n",
    "doc_word = vectorizer.fit_transform(speech_df.transcript)\n",
    "doc_word.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1076: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(441, 6)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_model = NMF(6)\n",
    "doc_topic = nmf_model.fit_transform(doc_word)\n",
    "doc_topic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'say'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = vectorizer.get_feature_names()\n",
    "words[27030]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = nmf_model.components_.argsort(axis=1)[:,-1:-11:-1]\n",
    "# topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic #00</th>\n",
       "      <td>just</td>\n",
       "      <td>like</td>\n",
       "      <td>know</td>\n",
       "      <td>think</td>\n",
       "      <td>im</td>\n",
       "      <td>dont</td>\n",
       "      <td>youre</td>\n",
       "      <td>people</td>\n",
       "      <td>want</td>\n",
       "      <td>make</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic #01</th>\n",
       "      <td>world</td>\n",
       "      <td>people</td>\n",
       "      <td>make</td>\n",
       "      <td>new</td>\n",
       "      <td>human</td>\n",
       "      <td>state</td>\n",
       "      <td>country</td>\n",
       "      <td>war</td>\n",
       "      <td>time</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic #02</th>\n",
       "      <td>say</td>\n",
       "      <td>know</td>\n",
       "      <td>tell</td>\n",
       "      <td>years</td>\n",
       "      <td>come</td>\n",
       "      <td>people</td>\n",
       "      <td>want</td>\n",
       "      <td>think</td>\n",
       "      <td>dont</td>\n",
       "      <td>look</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic #03</th>\n",
       "      <td>love</td>\n",
       "      <td>man</td>\n",
       "      <td>life</td>\n",
       "      <td>soul</td>\n",
       "      <td>god</td>\n",
       "      <td>men</td>\n",
       "      <td>make</td>\n",
       "      <td>like</td>\n",
       "      <td>come</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic #04</th>\n",
       "      <td>life</td>\n",
       "      <td>make</td>\n",
       "      <td>time</td>\n",
       "      <td>work</td>\n",
       "      <td>years</td>\n",
       "      <td>live</td>\n",
       "      <td>know</td>\n",
       "      <td>learn</td>\n",
       "      <td>want</td>\n",
       "      <td>school</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic #05</th>\n",
       "      <td>wonder</td>\n",
       "      <td>science</td>\n",
       "      <td>religion</td>\n",
       "      <td>question</td>\n",
       "      <td>make</td>\n",
       "      <td>cells</td>\n",
       "      <td>arts</td>\n",
       "      <td>ask</td>\n",
       "      <td>think</td>\n",
       "      <td>knowledge</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0        1         2         3      4       5        6  \\\n",
       "Topic #00    just     like      know     think     im    dont    youre   \n",
       "Topic #01   world   people      make       new  human   state  country   \n",
       "Topic #02     say     know      tell     years   come  people     want   \n",
       "Topic #03    love      man      life      soul    god     men     make   \n",
       "Topic #04    life     make      time      work  years    live     know   \n",
       "Topic #05  wonder  science  religion  question   make   cells     arts   \n",
       "\n",
       "                7      8          9  \n",
       "Topic #00  people   want       make  \n",
       "Topic #01     war   time      right  \n",
       "Topic #02   think   dont       look  \n",
       "Topic #03    like   come       live  \n",
       "Topic #04   learn   want     school  \n",
       "Topic #05     ask  think  knowledge  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_words = [[words[index] for index in topic] for topic in topics]\n",
    "pd.DataFrame(topic_words,index=['Topic #' + '{:02d}'.format(i) for i in range(6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_df['topic'] = doc_topic.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>year</th>\n",
       "      <th>transcript</th>\n",
       "      <th>length</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>GARRISON KEILLOR</td>\n",
       "      <td>0</td>\n",
       "      <td>its an honor to be with so many smart people a...</td>\n",
       "      <td>8063</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>JIMMY IOVINE</td>\n",
       "      <td>2013</td>\n",
       "      <td>to all of todays graduate i cant imagine whats...</td>\n",
       "      <td>14963</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>TRACY CHEVALIER</td>\n",
       "      <td>2013</td>\n",
       "      <td>greet president krislov graduate students fami...</td>\n",
       "      <td>16863</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>JON LOVETT</td>\n",
       "      <td>2013</td>\n",
       "      <td>i recently turn thirty which i know seem like ...</td>\n",
       "      <td>10804</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>JON STEWART</td>\n",
       "      <td>2004</td>\n",
       "      <td>thank you mr president i have forget how crush...</td>\n",
       "      <td>9613</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>SHARYN ALFONSI</td>\n",
       "      <td>2013</td>\n",
       "      <td>ole miss journalism and integrate market commu...</td>\n",
       "      <td>15057</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>THOMAS L FRIEDMAN</td>\n",
       "      <td>2005</td>\n",
       "      <td>it be an honor to stand before you this mornin...</td>\n",
       "      <td>22392</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>SETH MACFARLANE</td>\n",
       "      <td>2004</td>\n",
       "      <td>thank you very much i tell you there be nowher...</td>\n",
       "      <td>15994</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>DREW HOUSTON</td>\n",
       "      <td>2013</td>\n",
       "      <td>thank you chairman reed and congratulations to...</td>\n",
       "      <td>12132</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>NEIL DEGRASSE</td>\n",
       "      <td>2013</td>\n",
       "      <td>i thank you for this warm introduction and the...</td>\n",
       "      <td>6151</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               speaker  year  \\\n",
       "440   GARRISON KEILLOR     0   \n",
       "117       JIMMY IOVINE  2013   \n",
       "119    TRACY CHEVALIER  2013   \n",
       "120         JON LOVETT  2013   \n",
       "329        JON STEWART  2004   \n",
       "122     SHARYN ALFONSI  2013   \n",
       "324  THOMAS L FRIEDMAN  2005   \n",
       "339    SETH MACFARLANE  2004   \n",
       "126       DREW HOUSTON  2013   \n",
       "130      NEIL DEGRASSE  2013   \n",
       "\n",
       "                                            transcript  length  topic  \n",
       "440  its an honor to be with so many smart people a...    8063      0  \n",
       "117  to all of todays graduate i cant imagine whats...   14963      0  \n",
       "119  greet president krislov graduate students fami...   16863      0  \n",
       "120  i recently turn thirty which i know seem like ...   10804      0  \n",
       "329  thank you mr president i have forget how crush...    9613      0  \n",
       "122  ole miss journalism and integrate market commu...   15057      0  \n",
       "324  it be an honor to stand before you this mornin...   22392      0  \n",
       "339  thank you very much i tell you there be nowher...   15994      0  \n",
       "126  thank you chairman reed and congratulations to...   12132      0  \n",
       "130  i thank you for this warm introduction and the...    6151      0  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speech_df.sort_values('topic').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
