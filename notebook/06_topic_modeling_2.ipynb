{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "(Topic modeling continued)\n",
    "Use Tf-idf and NMF\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.feature_extraction import text \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from gensim import matutils, models\n",
    "import scipy.sparse\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('/Users/katiehuang/Desktop/metis/projects/onl_ds5_project_4/py')\n",
    "from word_cloud import *\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36156, 441)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's read in our transcripts and document-term matrix\n",
    "speech_df = pd.read_pickle('../dump/speech_clean_lemma')\n",
    "data = pd.read_pickle('../dump/data_dtm_lemma.pkl')\n",
    "tdm = data.transpose()\n",
    "tdm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Topic modeling - NMF\n",
    "\n",
    "Besides LDA, there are other matrix factorization techniques such as Latent Semantic Indexing (**LSI**) and non-negative Matrix Factorization (**NMF**).\n",
    "\n",
    "NMF is similar to Principal component analysis (**PCA**), but NMF models are interpretable. Vectors are non-negative; by factoring them into the lower-dimensional form, coefficients are also non-negative.\n",
    "\n",
    "- Documents are expressed as combinations of topics\n",
    "- Images are expressed as combinations of patterns\n",
    "\n",
    "NMF has components (dimension of components = dimension of samples)  \n",
    "> **sample = feature * components**  \n",
    "> (transcript = _____ * topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csr_mat = tfidf.fit_transform(speech_df['transcript'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(csr_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csr_mat.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aahhhh</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aback</th>\n",
       "      <th>abalthus</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abate</th>\n",
       "      <th>abbot</th>\n",
       "      <th>abbreviation</th>\n",
       "      <th>...</th>\n",
       "      <th>ôi</th>\n",
       "      <th>ômay</th>\n",
       "      <th>ôsobriety</th>\n",
       "      <th>ôtell</th>\n",
       "      <th>ôthe</th>\n",
       "      <th>ôwe</th>\n",
       "      <th>ôwhat</th>\n",
       "      <th>ôyou</th>\n",
       "      <th>ôyouõre</th>\n",
       "      <th>über</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows × 36466 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aa  aahhhh  aaron  aback  abalthus   abandon  abandonment  abate  abbot  \\\n",
       "0    0.0     0.0    0.0    0.0       0.0  0.012061          0.0    0.0    0.0   \n",
       "1    0.0     0.0    0.0    0.0       0.0  0.000000          0.0    0.0    0.0   \n",
       "2    0.0     0.0    0.0    0.0       0.0  0.000000          0.0    0.0    0.0   \n",
       "3    0.0     0.0    0.0    0.0       0.0  0.000000          0.0    0.0    0.0   \n",
       "4    0.0     0.0    0.0    0.0       0.0  0.000000          0.0    0.0    0.0   \n",
       "..   ...     ...    ...    ...       ...       ...          ...    ...    ...   \n",
       "436  0.0     0.0    0.0    0.0       0.0  0.000000          0.0    0.0    0.0   \n",
       "437  0.0     0.0    0.0    0.0       0.0  0.000000          0.0    0.0    0.0   \n",
       "438  0.0     0.0    0.0    0.0       0.0  0.000000          0.0    0.0    0.0   \n",
       "439  0.0     0.0    0.0    0.0       0.0  0.000000          0.0    0.0    0.0   \n",
       "440  0.0     0.0    0.0    0.0       0.0  0.000000          0.0    0.0    0.0   \n",
       "\n",
       "     abbreviation  ...   ôi  ômay  ôsobriety  ôtell  ôthe  ôwe  ôwhat  ôyou  \\\n",
       "0             0.0  ...  0.0   0.0        0.0    0.0   0.0  0.0    0.0   0.0   \n",
       "1             0.0  ...  0.0   0.0        0.0    0.0   0.0  0.0    0.0   0.0   \n",
       "2             0.0  ...  0.0   0.0        0.0    0.0   0.0  0.0    0.0   0.0   \n",
       "3             0.0  ...  0.0   0.0        0.0    0.0   0.0  0.0    0.0   0.0   \n",
       "4             0.0  ...  0.0   0.0        0.0    0.0   0.0  0.0    0.0   0.0   \n",
       "..            ...  ...  ...   ...        ...    ...   ...  ...    ...   ...   \n",
       "436           0.0  ...  0.0   0.0        0.0    0.0   0.0  0.0    0.0   0.0   \n",
       "437           0.0  ...  0.0   0.0        0.0    0.0   0.0  0.0    0.0   0.0   \n",
       "438           0.0  ...  0.0   0.0        0.0    0.0   0.0  0.0    0.0   0.0   \n",
       "439           0.0  ...  0.0   0.0        0.0    0.0   0.0  0.0    0.0   0.0   \n",
       "440           0.0  ...  0.0   0.0        0.0    0.0   0.0  0.0    0.0   0.0   \n",
       "\n",
       "     ôyouõre  über  \n",
       "0        0.0   0.0  \n",
       "1        0.0   0.0  \n",
       "2        0.0   0.0  \n",
       "3        0.0   0.0  \n",
       "4        0.0   0.0  \n",
       "..       ...   ...  \n",
       "436      0.0   0.0  \n",
       "437      0.0   0.0  \n",
       "438      0.0   0.0  \n",
       "439      0.0   0.0  \n",
       "440      0.0   0.0  \n",
       "\n",
       "[441 rows x 36466 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_dtm = pd.DataFrame(csr_mat.toarray(), columns=tfidf.get_feature_names())\n",
    "tfidf_dtm.index = speech_df.index\n",
    "tfidf_dtm.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle words to remove\n",
    "add_stop_words = ['like','youre','ive','im','really','id','ve','just','dont','didnt','thi','wa',\n",
    "                  'say','know','make','people']\n",
    "\n",
    "boring_words = ['say','like','just','dont','don','im',\n",
    "                'ive','youll','youve','things','thing','youre','right','really','lot',\n",
    "                'make','know','people','way','day','class',\n",
    "                'little', 'maybe','niagara','university','dartmouth','woman', 'womens','wellesley',\n",
    "                'shirtwaist','scripps','aidan','tuskegee','dr','colleges', 'guy', 'dave',\n",
    "                'arts','montgomery','girls']\n",
    "\n",
    "import pickle\n",
    "with open(\"../dump/common_words.txt\", \"rb\") as f:   # Unpickling\n",
    "    common_words = pickle.load(f)\n",
    "    \n",
    "add_stop_words = add_stop_words + common_words + boring_words\n",
    "\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(add_stop_words)\n",
    "# stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_dtm(df,column_name,add_stop_words=[]):\n",
    "    \"\"\"\n",
    "    Input: corpus (Ex: speech_clean_2, 'transcript')\n",
    "    Output: Document-Term Matrix (rows: documents, columns: words)\n",
    "    \n",
    "    \"\"\"\n",
    "    tfidf = TfidfVectorizer(stop_words=stop_words)\n",
    "    data_tfidf = tfidf.fit_transform(df[column_name])\n",
    "\n",
    "    tfidf_dtm = pd.DataFrame(data_tfidf.toarray(), columns=tfidf.get_feature_names())\n",
    "    tfidf_dtm.index = df.index\n",
    "    \n",
    "    return tfidf_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aahhhh</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aback</th>\n",
       "      <th>abalthus</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abate</th>\n",
       "      <th>abbot</th>\n",
       "      <th>abbreviation</th>\n",
       "      <th>...</th>\n",
       "      <th>ôi</th>\n",
       "      <th>ômay</th>\n",
       "      <th>ôsobriety</th>\n",
       "      <th>ôtell</th>\n",
       "      <th>ôthe</th>\n",
       "      <th>ôwe</th>\n",
       "      <th>ôwhat</th>\n",
       "      <th>ôyou</th>\n",
       "      <th>ôyouõre</th>\n",
       "      <th>über</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021631</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows × 36100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aa  aahhhh  aaron  aback  abalthus   abandon  abandonment  abate  abbot  \\\n",
       "0    0.0     0.0    0.0    0.0       0.0  0.021631          0.0    0.0    0.0   \n",
       "1    0.0     0.0    0.0    0.0       0.0  0.000000          0.0    0.0    0.0   \n",
       "2    0.0     0.0    0.0    0.0       0.0  0.000000          0.0    0.0    0.0   \n",
       "3    0.0     0.0    0.0    0.0       0.0  0.000000          0.0    0.0    0.0   \n",
       "4    0.0     0.0    0.0    0.0       0.0  0.000000          0.0    0.0    0.0   \n",
       "..   ...     ...    ...    ...       ...       ...          ...    ...    ...   \n",
       "436  0.0     0.0    0.0    0.0       0.0  0.000000          0.0    0.0    0.0   \n",
       "437  0.0     0.0    0.0    0.0       0.0  0.000000          0.0    0.0    0.0   \n",
       "438  0.0     0.0    0.0    0.0       0.0  0.000000          0.0    0.0    0.0   \n",
       "439  0.0     0.0    0.0    0.0       0.0  0.000000          0.0    0.0    0.0   \n",
       "440  0.0     0.0    0.0    0.0       0.0  0.000000          0.0    0.0    0.0   \n",
       "\n",
       "     abbreviation  ...   ôi  ômay  ôsobriety  ôtell  ôthe  ôwe  ôwhat  ôyou  \\\n",
       "0             0.0  ...  0.0   0.0        0.0    0.0   0.0  0.0    0.0   0.0   \n",
       "1             0.0  ...  0.0   0.0        0.0    0.0   0.0  0.0    0.0   0.0   \n",
       "2             0.0  ...  0.0   0.0        0.0    0.0   0.0  0.0    0.0   0.0   \n",
       "3             0.0  ...  0.0   0.0        0.0    0.0   0.0  0.0    0.0   0.0   \n",
       "4             0.0  ...  0.0   0.0        0.0    0.0   0.0  0.0    0.0   0.0   \n",
       "..            ...  ...  ...   ...        ...    ...   ...  ...    ...   ...   \n",
       "436           0.0  ...  0.0   0.0        0.0    0.0   0.0  0.0    0.0   0.0   \n",
       "437           0.0  ...  0.0   0.0        0.0    0.0   0.0  0.0    0.0   0.0   \n",
       "438           0.0  ...  0.0   0.0        0.0    0.0   0.0  0.0    0.0   0.0   \n",
       "439           0.0  ...  0.0   0.0        0.0    0.0   0.0  0.0    0.0   0.0   \n",
       "440           0.0  ...  0.0   0.0        0.0    0.0   0.0  0.0    0.0   0.0   \n",
       "\n",
       "     ôyouõre  über  \n",
       "0        0.0   0.0  \n",
       "1        0.0   0.0  \n",
       "2        0.0   0.0  \n",
       "3        0.0   0.0  \n",
       "4        0.0   0.0  \n",
       "..       ...   ...  \n",
       "436      0.0   0.0  \n",
       "437      0.0   0.0  \n",
       "438      0.0   0.0  \n",
       "439      0.0   0.0  \n",
       "440      0.0   0.0  \n",
       "\n",
       "[441 rows x 36100 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_word = tfidf_dtm(speech_df,'transcript')\n",
    "doc_word.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(441, 6)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use NMF model, specify number of topics\n",
    "# (Following Vinny's lecture)\n",
    "nmf_model = NMF(6, max_iter=800)\n",
    "doc_topic = nmf_model.fit_transform(doc_word)\n",
    "doc_topic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic #00</th>\n",
       "      <td>write</td>\n",
       "      <td>try</td>\n",
       "      <td>happen</td>\n",
       "      <td>advice</td>\n",
       "      <td>start</td>\n",
       "      <td>ask</td>\n",
       "      <td>talk</td>\n",
       "      <td>thank</td>\n",
       "      <td>parent</td>\n",
       "      <td>remember</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic #01</th>\n",
       "      <td>america</td>\n",
       "      <td>government</td>\n",
       "      <td>war</td>\n",
       "      <td>country</td>\n",
       "      <td>nations</td>\n",
       "      <td>unite</td>\n",
       "      <td>education</td>\n",
       "      <td>state</td>\n",
       "      <td>human</td>\n",
       "      <td>nation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic #02</th>\n",
       "      <td>women</td>\n",
       "      <td>men</td>\n",
       "      <td>factory</td>\n",
       "      <td>workers</td>\n",
       "      <td>mean</td>\n",
       "      <td>lean</td>\n",
       "      <td>mother</td>\n",
       "      <td>triangle</td>\n",
       "      <td>privilege</td>\n",
       "      <td>feminist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic #03</th>\n",
       "      <td>company</td>\n",
       "      <td>business</td>\n",
       "      <td>purpose</td>\n",
       "      <td>start</td>\n",
       "      <td>career</td>\n",
       "      <td>technology</td>\n",
       "      <td>dream</td>\n",
       "      <td>build</td>\n",
       "      <td>journey</td>\n",
       "      <td>passion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic #04</th>\n",
       "      <td>dream</td>\n",
       "      <td>team</td>\n",
       "      <td>coach</td>\n",
       "      <td>play</td>\n",
       "      <td>game</td>\n",
       "      <td>football</td>\n",
       "      <td>win</td>\n",
       "      <td>tennis</td>\n",
       "      <td>ball</td>\n",
       "      <td>baseball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic #05</th>\n",
       "      <td>fear</td>\n",
       "      <td>experience</td>\n",
       "      <td>art</td>\n",
       "      <td>human</td>\n",
       "      <td>mind</td>\n",
       "      <td>present</td>\n",
       "      <td>feel</td>\n",
       "      <td>practice</td>\n",
       "      <td>science</td>\n",
       "      <td>simply</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0           1        2        3        4           5  \\\n",
       "Topic #00    write         try   happen   advice    start         ask   \n",
       "Topic #01  america  government      war  country  nations       unite   \n",
       "Topic #02    women         men  factory  workers     mean        lean   \n",
       "Topic #03  company    business  purpose    start   career  technology   \n",
       "Topic #04    dream        team    coach     play     game    football   \n",
       "Topic #05     fear  experience      art    human     mind     present   \n",
       "\n",
       "                   6         7          8         9  \n",
       "Topic #00       talk     thank     parent  remember  \n",
       "Topic #01  education     state      human    nation  \n",
       "Topic #02     mother  triangle  privilege  feminist  \n",
       "Topic #03      dream     build    journey   passion  \n",
       "Topic #04        win    tennis       ball  baseball  \n",
       "Topic #05       feel  practice    science    simply  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use components in NMF model to find the top 10 words for a given topic\n",
    "topics = nmf_model.components_.argsort(axis=1)[:,-1:-11:-1]\n",
    "\n",
    "# Create topic_worrd df\n",
    "words = doc_word.columns\n",
    "topic_words = [[words[index] for index in topic] for topic in topics]\n",
    "pd.DataFrame(topic_words,index=['Topic #' + '{:02d}'.format(i) for i in range(6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36102"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means (clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(svd,kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('truncatedsvd', TruncatedSVD(n_components=50)),\n",
       "                ('kmeans', KMeans(n_clusters=6))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(csr_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pipeline.predict(csr_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = list(speech_df.speaker)\n",
    "# speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     label              speaker\n",
      "314      0      ESTELLE PARSONS\n",
      "258      0         CARL SCHRAMM\n",
      "181      0  ARRIANNA HUFFINGTON\n",
      "412      0         SUSAN SONTAG\n",
      "386      0           CARL SAGAN\n",
      "..     ...                  ...\n",
      "245      4           JERRY YANG\n",
      "169      4         FRED ARMISEN\n",
      "52       4          RON SUSKIND\n",
      "69       4             ED HELMS\n",
      "49       5           JACK BLACK\n",
      "\n",
      "[441 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'label': labels, 'speaker': speakers})\n",
    "print(df.sort_values('label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF (DataCamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NMF(n_components=6)\n",
    "model.fit(csr_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_features = model.transform(csr_mat)\n",
    "# nmf_features\n",
    "\n",
    "# Normalize the NMF features\n",
    "from sklearn.preprocessing import normalize\n",
    "norm_features = normalize(nmf_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(nmf_features,index=speakers)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommender: cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommender using cosine similarity\n",
    "\n",
    "df = pd.DataFrame(norm_features,index=speakers)\n",
    "transcript = df.iloc[0]\n",
    "similarities = df.dot(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find speeches most similar to that of SIDDHARTHA MUKHERJEE\n",
    "print(similarities.nlargest())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(similarities.nsmallest())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF (Vinny's lecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(441, 36168)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words = 'english')\n",
    "doc_word = vectorizer.fit_transform(speech_df.transcript)\n",
    "doc_word.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<441x36168 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 234140 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1076: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(441, 6)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_model = NMF(6)\n",
    "doc_topic = nmf_model.fit_transform(doc_word)\n",
    "doc_topic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'say'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = vectorizer.get_feature_names()\n",
    "words[27030]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = nmf_model.components_.argsort(axis=1)[:,-1:-11:-1]\n",
    "# topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic #00</th>\n",
       "      <td>just</td>\n",
       "      <td>like</td>\n",
       "      <td>know</td>\n",
       "      <td>think</td>\n",
       "      <td>im</td>\n",
       "      <td>dont</td>\n",
       "      <td>youre</td>\n",
       "      <td>people</td>\n",
       "      <td>want</td>\n",
       "      <td>make</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic #01</th>\n",
       "      <td>world</td>\n",
       "      <td>people</td>\n",
       "      <td>make</td>\n",
       "      <td>new</td>\n",
       "      <td>human</td>\n",
       "      <td>state</td>\n",
       "      <td>country</td>\n",
       "      <td>war</td>\n",
       "      <td>time</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic #02</th>\n",
       "      <td>say</td>\n",
       "      <td>know</td>\n",
       "      <td>tell</td>\n",
       "      <td>years</td>\n",
       "      <td>come</td>\n",
       "      <td>people</td>\n",
       "      <td>want</td>\n",
       "      <td>think</td>\n",
       "      <td>dont</td>\n",
       "      <td>look</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic #03</th>\n",
       "      <td>love</td>\n",
       "      <td>man</td>\n",
       "      <td>life</td>\n",
       "      <td>soul</td>\n",
       "      <td>god</td>\n",
       "      <td>men</td>\n",
       "      <td>make</td>\n",
       "      <td>like</td>\n",
       "      <td>come</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic #04</th>\n",
       "      <td>life</td>\n",
       "      <td>make</td>\n",
       "      <td>time</td>\n",
       "      <td>work</td>\n",
       "      <td>years</td>\n",
       "      <td>live</td>\n",
       "      <td>know</td>\n",
       "      <td>learn</td>\n",
       "      <td>want</td>\n",
       "      <td>school</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic #05</th>\n",
       "      <td>wonder</td>\n",
       "      <td>science</td>\n",
       "      <td>religion</td>\n",
       "      <td>question</td>\n",
       "      <td>make</td>\n",
       "      <td>cells</td>\n",
       "      <td>arts</td>\n",
       "      <td>ask</td>\n",
       "      <td>think</td>\n",
       "      <td>knowledge</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0        1         2         3      4       5        6  \\\n",
       "Topic #00    just     like      know     think     im    dont    youre   \n",
       "Topic #01   world   people      make       new  human   state  country   \n",
       "Topic #02     say     know      tell     years   come  people     want   \n",
       "Topic #03    love      man      life      soul    god     men     make   \n",
       "Topic #04    life     make      time      work  years    live     know   \n",
       "Topic #05  wonder  science  religion  question   make   cells     arts   \n",
       "\n",
       "                7      8          9  \n",
       "Topic #00  people   want       make  \n",
       "Topic #01     war   time      right  \n",
       "Topic #02   think   dont       look  \n",
       "Topic #03    like   come       live  \n",
       "Topic #04   learn   want     school  \n",
       "Topic #05     ask  think  knowledge  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_words = [[words[index] for index in topic] for topic in topics]\n",
    "pd.DataFrame(topic_words,index=['Topic #' + '{:02d}'.format(i) for i in range(6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_df['topic'] = doc_topic.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>year</th>\n",
       "      <th>transcript</th>\n",
       "      <th>length</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>GARRISON KEILLOR</td>\n",
       "      <td>0</td>\n",
       "      <td>its an honor to be with so many smart people a...</td>\n",
       "      <td>8063</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>SETH MACFARLANE</td>\n",
       "      <td>2004</td>\n",
       "      <td>thank you very much i tell you there be nowher...</td>\n",
       "      <td>15994</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>JIMMY IOVINE</td>\n",
       "      <td>2013</td>\n",
       "      <td>to all of todays graduate i cant imagine whats...</td>\n",
       "      <td>14963</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>TRACY CHEVALIER</td>\n",
       "      <td>2013</td>\n",
       "      <td>greet president krislov graduate students fami...</td>\n",
       "      <td>16863</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>JON LOVETT</td>\n",
       "      <td>2013</td>\n",
       "      <td>i recently turn thirty which i know seem like ...</td>\n",
       "      <td>10804</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>JON STEWART</td>\n",
       "      <td>2004</td>\n",
       "      <td>thank you mr president i have forget how crush...</td>\n",
       "      <td>9613</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>SHARYN ALFONSI</td>\n",
       "      <td>2013</td>\n",
       "      <td>ole miss journalism and integrate market commu...</td>\n",
       "      <td>15057</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>WILL FERRELL</td>\n",
       "      <td>2003</td>\n",
       "      <td>this be not the worcester mass boat show be it...</td>\n",
       "      <td>10594</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>THOMAS L FRIEDMAN</td>\n",
       "      <td>2005</td>\n",
       "      <td>it be an honor to stand before you this mornin...</td>\n",
       "      <td>22392</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>ED HELMS</td>\n",
       "      <td>2013</td>\n",
       "      <td>hello knox collegethank you students faculty p...</td>\n",
       "      <td>10506</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               speaker  year  \\\n",
       "440   GARRISON KEILLOR     0   \n",
       "339    SETH MACFARLANE  2004   \n",
       "117       JIMMY IOVINE  2013   \n",
       "119    TRACY CHEVALIER  2013   \n",
       "120         JON LOVETT  2013   \n",
       "329        JON STEWART  2004   \n",
       "122     SHARYN ALFONSI  2013   \n",
       "345       WILL FERRELL  2003   \n",
       "324  THOMAS L FRIEDMAN  2005   \n",
       "127           ED HELMS  2013   \n",
       "\n",
       "                                            transcript  length  topic  \n",
       "440  its an honor to be with so many smart people a...    8063      0  \n",
       "339  thank you very much i tell you there be nowher...   15994      0  \n",
       "117  to all of todays graduate i cant imagine whats...   14963      0  \n",
       "119  greet president krislov graduate students fami...   16863      0  \n",
       "120  i recently turn thirty which i know seem like ...   10804      0  \n",
       "329  thank you mr president i have forget how crush...    9613      0  \n",
       "122  ole miss journalism and integrate market commu...   15057      0  \n",
       "345  this be not the worcester mass boat show be it...   10594      0  \n",
       "324  it be an honor to stand before you this mornin...   22392      0  \n",
       "127  hello knox collegethank you students faculty p...   10506      0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speech_df.sort_values('topic').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
